{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f5de296-05cd-40a3-b77d-5cf70e056fe5",
   "metadata": {},
   "source": [
    "## VC-SD: Demonstration\n",
    "\n",
    "This script demonstrate the voice conversion, voice design and controllability of the VC-SD framework. Please note, this script is for demonstration purposes only, final models, training schemes, practical implementation etc. is not provided.\n",
    "\n",
    "For each example you can choose the audio files from the current repository or upload from your own PC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba5ab3-a344-4ffd-8447-9615435083e5",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457c1e3d-b5a8-4f40-9349-60498da3eab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets>=8.0.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/tljh/user/lib/python3.12/site-packages (from ipywidgets>=8.0.0) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/tljh/user/lib/python3.12/site-packages (from ipywidgets>=8.0.0) (9.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/tljh/user/lib/python3.12/site-packages (from ipywidgets>=8.0.0) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from ipywidgets>=8.0.0) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/tljh/user/lib/python3.12/site-packages (from ipywidgets>=8.0.0) (3.0.15)\n",
      "Requirement already satisfied: decorator in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/tljh/user/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/tljh/user/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/tljh/user/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/tljh/user/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/tljh/user/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.0) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/tljh/user/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.0) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/tljh/user/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.0) (0.2.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/jupyter-arbu/.local/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: librosa in /home/jupyter-arbu/.local/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in /home/jupyter-arbu/.local/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: descript-audiotools in /home/jupyter-arbu/.local/lib/python3.12/site-packages (0.7.4)\n",
      "Requirement already satisfied: torchfcpe in /home/jupyter-arbu/.local/lib/python3.12/site-packages (0.0.4)\n",
      "Requirement already satisfied: ipyfilechooser in /home/jupyter-arbu/.local/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: filelock in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/tljh/user/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/tljh/user/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/tljh/user/lib/python3.12/site-packages (from torch) (74.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/tljh/user/lib/python3.12/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: argbind in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.3.9)\n",
      "Requirement already satisfied: pyloudnorm in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.1.1)\n",
      "Requirement already satisfied: importlib-resources in /opt/tljh/user/lib/python3.12/site-packages (from descript-audiotools) (6.5.2)\n",
      "Requirement already satisfied: julius in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.2.7)\n",
      "Requirement already satisfied: torchaudio in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (2.5.1)\n",
      "Requirement already satisfied: ffmpy in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.5.0)\n",
      "Requirement already satisfied: ipython in /opt/tljh/user/lib/python3.12/site-packages (from descript-audiotools) (9.2.0)\n",
      "Requirement already satisfied: rich in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (14.0.0)\n",
      "Requirement already satisfied: matplotlib in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (3.10.1)\n",
      "Requirement already satisfied: pystoi in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.4.1)\n",
      "Requirement already satisfied: torch-stoi in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.2.3)\n",
      "Requirement already satisfied: flatten-dict in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.4.2)\n",
      "Requirement already satisfied: markdown2 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (2.5.3)\n",
      "Requirement already satisfied: randomname in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (0.2.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (4.25.7)\n",
      "Requirement already satisfied: tensorboard in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (2.19.0)\n",
      "Requirement already satisfied: tqdm in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from descript-audiotools) (4.67.1)\n",
      "Requirement already satisfied: einops in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torchfcpe) (0.8.1)\n",
      "Requirement already satisfied: local-attention in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from torchfcpe) (1.11.1)\n",
      "Requirement already satisfied: ipywidgets in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from ipyfilechooser) (8.1.8)\n",
      "Requirement already satisfied: packaging in /opt/tljh/user/lib/python3.12/site-packages (from lazy_loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/tljh/user/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/tljh/user/lib/python3.12/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/tljh/user/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pyyaml in /opt/tljh/user/lib/python3.12/site-packages (from argbind->descript-audiotools) (6.0.2)\n",
      "Requirement already satisfied: docstring-parser in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from argbind->descript-audiotools) (0.16)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in /opt/tljh/user/lib/python3.12/site-packages (from flatten-dict->descript-audiotools) (1.17.0)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/tljh/user/lib/python3.12/site-packages (from ipython->descript-audiotools) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/tljh/user/lib/python3.12/site-packages (from ipywidgets->ipyfilechooser) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from ipywidgets->ipyfilechooser) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/tljh/user/lib/python3.12/site-packages (from ipywidgets->ipyfilechooser) (3.0.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/tljh/user/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: hyper-connections>=0.1.8 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from local-attention->torchfcpe) (0.1.15)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from matplotlib->descript-audiotools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from matplotlib->descript-audiotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from matplotlib->descript-audiotools) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from matplotlib->descript-audiotools) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from matplotlib->descript-audiotools) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from matplotlib->descript-audiotools) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/tljh/user/lib/python3.12/site-packages (from matplotlib->descript-audiotools) (2.9.0.post0)\n",
      "Requirement already satisfied: future>=0.16.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from pyloudnorm->descript-audiotools) (1.0.0)\n",
      "Requirement already satisfied: fire in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from randomname->descript-audiotools) (0.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from rich->descript-audiotools) (3.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from tensorboard->descript-audiotools) (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from tensorboard->descript-audiotools) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from tensorboard->descript-audiotools) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from tensorboard->descript-audiotools) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from tensorboard->descript-audiotools) (3.1.3)\n",
      "Requirement already satisfied: pycparser in /opt/tljh/user/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/tljh/user/lib/python3.12/site-packages (from jedi>=0.16->ipython->descript-audiotools) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->descript-audiotools) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/tljh/user/lib/python3.12/site-packages (from pexpect>4.3->ipython->descript-audiotools) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/tljh/user/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->descript-audiotools) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Requirement already satisfied: termcolor in /home/jupyter-arbu/.local/lib/python3.12/site-packages (from fire->randomname->descript-audiotools) (3.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/tljh/user/lib/python3.12/site-packages (from stack_data->ipython->descript-audiotools) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/tljh/user/lib/python3.12/site-packages (from stack_data->ipython->descript-audiotools) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/tljh/user/lib/python3.12/site-packages (from stack_data->ipython->descript-audiotools) (0.2.3)\n",
      "All libraries installed successfully!\n"
     ]
    }
   ],
   "source": [
    "!pip install \"ipywidgets>=8.0.0\"\n",
    "!pip install torch librosa numpy descript-audiotools torchfcpe ipyfilechooser\n",
    "\n",
    "print(\"All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16fd45-900d-4571-bdcf-58a9071d2b6c",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae3c903-778b-4fb6-9fde-eeb3636d4415",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from utils.demo_utils import *\n",
    "from audiotools import transforms as tfm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def linear_map(x, src_min, src_max, dst_min, dst_max):\n",
    "    x = np.clip(x, src_min, src_max)\n",
    "    return dst_min + (x - src_min) * (dst_max - dst_min) / (src_max - src_min)\n",
    "\n",
    "def years_to_age_param(years):\n",
    "    \"\"\"Convert years back to age parameter\"\"\"\n",
    "    return linear_map(\n",
    "        years,\n",
    "        src_min=15,\n",
    "        src_max=90,\n",
    "        dst_min=-0.75,\n",
    "        dst_max=3.5,\n",
    "    )\n",
    "\n",
    "def semitones_to_pitch(semitones):\n",
    "    \"\"\"Convert semitones to pitch multiplier (octaves)\"\"\"\n",
    "    return 2 ** (semitones / 12.0)\n",
    "\n",
    "def gender_param_to_label(gender_param):\n",
    "    \"\"\"Convert gender parameter to label\"\"\"\n",
    "    if gender_param < 0:\n",
    "        return \"Male\"\n",
    "    else:\n",
    "        return \"Female\"\n",
    "\n",
    "def make_audio_picker(label, default_value):\n",
    "    class PickerState:\n",
    "        value = default_value\n",
    "        uploaded_audio = None \n",
    "\n",
    "    state = PickerState()\n",
    "\n",
    "    selected_label = widgets.HTML(\n",
    "        value=f'<span style=\"color:#555\">üìÑ Current file: <b>{os.path.basename(default_value)}</b></span>'\n",
    "    )\n",
    "\n",
    "    def update_label(fname):\n",
    "        selected_label.value = f'<span style=\"color:#1a7a1a\">üìÑ Current file: <b>{os.path.basename(fname)}</b></span>'\n",
    "\n",
    "    mode_toggle = widgets.ToggleButtons(\n",
    "        options=['üìÅ Browse Here', 'üíª Upload'],\n",
    "        description='',\n",
    "        button_style='',\n",
    "        layout=widgets.Layout(margin='0 0 6px 0')\n",
    "    )\n",
    "\n",
    "    fc = FileChooser(\n",
    "        path=os.path.dirname(default_value) if os.path.dirname(default_value) else '.',\n",
    "        filter_pattern=['*.wav', '*.mp3', '*.flac'],\n",
    "        title=f'<b>{label}</b>'\n",
    "    )\n",
    "\n",
    "    def on_fc_change(chooser):\n",
    "        if chooser.selected:\n",
    "            state.value = chooser.selected\n",
    "            state.uploaded_audio = None\n",
    "            update_label(chooser.selected)\n",
    "\n",
    "    fc.register_callback(on_fc_change)\n",
    "    fc_box = widgets.VBox([fc])\n",
    "\n",
    "    upload_widget = widgets.FileUpload(\n",
    "        accept='.wav,.mp3,.flac',\n",
    "        multiple=False,\n",
    "        description='Upload Audio',\n",
    "        layout=widgets.Layout(width='250px')\n",
    "    )\n",
    "    upload_status = widgets.Label(value='No file uploaded yet.')\n",
    "\n",
    "    def on_upload(change):\n",
    "        if upload_widget.value:\n",
    "            uploaded = list(upload_widget.value.values())[0] \\\n",
    "                if isinstance(upload_widget.value, dict) \\\n",
    "                else upload_widget.value[0]\n",
    "\n",
    "            fname   = uploaded['metadata']['name'] \\\n",
    "                if 'metadata' in uploaded else uploaded['name']\n",
    "            content = uploaded['content'] \\\n",
    "                if 'content' in uploaded else uploaded['data']\n",
    "\n",
    "            audio_bytes = io.BytesIO(bytes(content))\n",
    "            samples, sr = librosa.load(audio_bytes, sr=16000, mono=True)\n",
    "\n",
    "            state.value = fname\n",
    "            state.uploaded_audio = (samples, sr)\n",
    "            upload_status.value = f'‚úÖ Loaded: {fname}  ({len(samples)/sr:.2f}s)'\n",
    "            update_label(fname)\n",
    "\n",
    "    upload_widget.observe(on_upload, names='value')\n",
    "\n",
    "    pc_box = widgets.VBox([upload_widget, upload_status])\n",
    "    pc_box.layout.display = 'none'\n",
    "\n",
    "    def on_toggle(change):\n",
    "        if change['new'] == 'üìÅ Browse Here':\n",
    "            fc_box.layout.display = ''\n",
    "            pc_box.layout.display = 'none'\n",
    "            state.uploaded_audio = None\n",
    "            if fc.selected:\n",
    "                state.value = fc.selected\n",
    "                update_label(fc.selected)\n",
    "        else:\n",
    "            fc_box.layout.display = 'none'\n",
    "            pc_box.layout.display = ''\n",
    "\n",
    "    mode_toggle.observe(on_toggle, names='value')\n",
    "\n",
    "    header = widgets.HTML(f'<b style=\"font-size:14px\">{label}</b>')\n",
    "    container = widgets.VBox([\n",
    "        widgets.HBox(\n",
    "            [header, selected_label],\n",
    "            layout=widgets.Layout(\n",
    "                justify_content='space-between',\n",
    "                align_items='center',\n",
    "                width='100%'\n",
    "            )\n",
    "        ),\n",
    "        mode_toggle,\n",
    "        fc_box,\n",
    "        pc_box,\n",
    "    ], layout=widgets.Layout(\n",
    "        border='1px solid #ccc',\n",
    "        padding='8px',\n",
    "        margin='4px 0',\n",
    "        border_radius='6px'\n",
    "    ))\n",
    "\n",
    "    return container, state\n",
    "\n",
    "transform = tfm.Compose(\n",
    "            tfm.VolumeNorm(),\n",
    "            tfm.RescaleAudio())\n",
    "\n",
    "vc_model = torch.jit.load(\"pretrained/model-nc.ts\")\n",
    "vc_model = vc_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be75ac0-fa16-408a-ba5d-f46919b77a7f",
   "metadata": {},
   "source": [
    "## Voice Design\n",
    "\n",
    "In the next cell, you‚Äôll be able to transform a voice using simple, interactive controls.\n",
    "\n",
    "Run the cell, then use the sliders to design a new voice profile for your input audio. Feel free to experiment ‚Äî even small adjustments can noticeably change the result.\n",
    "\n",
    "---\n",
    "\n",
    "### Controls\n",
    "\n",
    "- **Audio File**: Select the audio file you want to convert. To use a different file, simply change the file path.\n",
    "\n",
    "- **Gender**: Adjusts the perceived timbre of the voice: **-1.72** ‚Üí more typically masculine, **1.94** ‚Üí more typically feminine.\n",
    "      \n",
    "- **Age**: Changes the perceived age of the output. Due to age cues being subtle, this can be thought of as a timbre variation control.\n",
    "\n",
    "- **Tremble**: Adds a tremble (vibrato-like effect) to the voice: **0** ‚Üí no tremble, **12** ‚Üí strong tremble. \n",
    "\n",
    "- **Ambitus**: Controls how expressive the voice sounds: **0.5** ‚Üí flatter, more robotic, **1.5** ‚Üí wider pitch range, more emotional.\n",
    "\n",
    "- **Pitch**: Shifts the overall pitch of the converted voice up or down.\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Tip:** Try adjusting one slider at a time to clearly hear what each parameter changes ‚Äî then combine them to craft unique voice styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3317ac5a-6ce8-4bb8-982e-5ab490a8a13b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab1b36b98d443c3ad240c596708d187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<b style=\"font-size:14px\">Input Audio</b>'), HTML(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_container, input_state = make_audio_picker('Input Audio', 'audio/librispeech2.wav')\n",
    "\n",
    "gender_slider  = widgets.FloatSlider(value=-0.1, min=-1.72, max=1.94, step=0.01, description='Gender:', continuous_update=False)\n",
    "age_slider     = widgets.IntSlider(value=35, min=15, max=90, step=1, description='Age (years):', continuous_update=False)\n",
    "tremble_slider = widgets.FloatSlider(value=1.0, min=0.0, max=12.0, step=0.1, description='Tremble:', continuous_update=False)\n",
    "ambitus_slider = widgets.FloatSlider(value=1.0, min=0.5, max=1.5, step=0.01, description='Ambitus:', continuous_update=False)\n",
    "pitch_slider   = widgets.IntSlider(value=0, min=-12, max=12, step=1, description='Pitch (semitones):', continuous_update=False)\n",
    "\n",
    "gender_label  = widgets.Label(value='Male (-1.72) ‚Üí Female (1.94)')\n",
    "age_label     = widgets.Label(value='Age in years')\n",
    "tremble_label = widgets.Label(value='Tremble Amount')\n",
    "ambitus_label = widgets.Label(value='Pitch Variance')\n",
    "pitch_label   = widgets.Label(value='-12 to +12 semitones')\n",
    "\n",
    "process_button = widgets.Button(description='Process Audio', button_style='success')\n",
    "output_age_gender = widgets.Output()\n",
    "\n",
    "def process_audio(b):\n",
    "    with output_age_gender:\n",
    "        output_age_gender.clear_output()\n",
    "\n",
    "        gender     = gender_slider.value\n",
    "        age_years  = age_slider.value\n",
    "        age        = years_to_age_param(age_years)\n",
    "        tremble    = tremble_slider.value\n",
    "        ambitus    = ambitus_slider.value\n",
    "        semitones  = pitch_slider.value\n",
    "        pitch      = semitones_to_pitch(semitones)\n",
    "\n",
    "        print(f\"Audio file: {input_state.value}\")\n",
    "        print(f\"Gender:     {gender_param_to_label(gender)}\")\n",
    "        print(f\"Age:        {age_years} years\")\n",
    "        print(f\"Tremble:    {tremble}\")\n",
    "        print(f\"Ambitus:    {ambitus}\")\n",
    "        print(f\"Pitch:      {semitones:+d} semitones\")\n",
    "        print()\n",
    "\n",
    "        try:\n",
    "            x_np, sr = load_audio_from_state(input_state)\n",
    "            x = torch.tensor(x_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            speaker_gender  = torch.tensor([gender],  dtype=torch.float32)\n",
    "            speaker_age     = torch.tensor([age],     dtype=torch.float32)\n",
    "            speaker_tremble = torch.tensor([tremble], dtype=torch.float32)\n",
    "            speaker_ambitus = torch.tensor([ambitus], dtype=torch.float32)\n",
    "            speaker_pitch   = torch.tensor([pitch],   dtype=torch.float32)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                vc_model.reset_pitch()\n",
    "                vc_model.set_new_speaker(speaker_gender, speaker_age)\n",
    "                vc_model.set_tremble_depth(speaker_tremble)\n",
    "                vc_model.set_ambitus_scaler(speaker_ambitus)\n",
    "                vc_model.set_pitch_mult(speaker_pitch)\n",
    "\n",
    "            out = vc_model(normalize(x, transform))\n",
    "\n",
    "            display_audios([(\"INPUT\", x, sr), (\"CONVERTED\", out, sr)])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "process_button.on_click(process_audio)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    input_container,\n",
    "    widgets.HBox([gender_slider,  gender_label]),\n",
    "    widgets.HBox([age_slider,     age_label]),\n",
    "    widgets.HBox([tremble_slider, tremble_label]),\n",
    "    widgets.HBox([ambitus_slider, ambitus_label]),\n",
    "    widgets.HBox([pitch_slider,   pitch_label]),\n",
    "    process_button,\n",
    "    output_age_gender\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29561a7b-3539-4dfc-bd81-b59ca9d7665d",
   "metadata": {},
   "source": [
    "## Convert by Audio Reference\n",
    "\n",
    "Instead of designing a voice with sliders, you can also **convert your input to match a reference recording**.\n",
    "\n",
    "Simply provide a **target audio file**, and the system will analyze its vocal characteristics, such as timbre, and tone, and apply them to your input audio.\n",
    "\n",
    "**In short**: Input content + reference voice = your message, delivered in a new vocal style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd6ac8e-c518-45e7-8a63-22190543ea60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0bdb8bf40540e4bd059798cbfcffa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<b style=\"font-size:14px\">Input Audio</b>'), HTML(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_container,  input_state  = make_audio_picker('Input Audio',  'audio/librispeech2.wav')\n",
    "target_container, target_state = make_audio_picker('Target Audio', 'targets/p228_004.wav')\n",
    "\n",
    "target_start_sample = widgets.IntText(\n",
    "    value=8000,\n",
    "    description='Target Start (in samples):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "process_button = widgets.Button(description='Process Audio', button_style='success')\n",
    "output_reference = widgets.Output()\n",
    "\n",
    "def load_audio_from_state(state, start_idx=0):\n",
    "    \"\"\"Load audio either from an uploaded buffer or from a file path.\"\"\"\n",
    "    if state.uploaded_audio is not None:\n",
    "        samples, sr = state.uploaded_audio\n",
    "    else:\n",
    "        if not os.path.isfile(state.value):\n",
    "            raise FileNotFoundError(f\"File not found: '{state.value}'\")\n",
    "        samples, sr = librosa.load(state.value, sr=16000, mono=True)\n",
    "    return samples[start_idx:], sr\n",
    "\n",
    "def process_audio(b):\n",
    "    with output_reference:\n",
    "        output_reference.clear_output()\n",
    "        try:\n",
    "            start_idx = target_start_sample.value\n",
    "\n",
    "            x_np, sr = load_audio_from_state(input_state)\n",
    "            x = torch.tensor(x_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            t_np, sr = load_audio_from_state(target_state, start_idx=start_idx)\n",
    "            t = torch.tensor(t_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            print(f\"Input audio:  {input_state.value}\")\n",
    "            print(f\"Target audio: {target_state.value}\")\n",
    "            print(f\"Start sample: {start_idx}\")\n",
    "            print()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                vc_model.reset_pitch()\n",
    "                vc_model.set_embedding_from_audio(t)\n",
    "                vc_model.set_tremble_depth(torch.zeros(1, dtype=torch.float32))\n",
    "                vc_model.set_ambitus_scaler(torch.ones(1, dtype=torch.float32))\n",
    "                vc_model.set_pitch_mult(torch.ones(1, dtype=torch.float32))\n",
    "\n",
    "            out = vc_model(normalize(x, transform))\n",
    "            display_audios([(\"INPUT\", x, sr), (\"TARGET\", t, sr), (\"CONVERTED\", out, sr)])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "process_button.on_click(process_audio)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    input_container,\n",
    "    target_container,\n",
    "    target_start_sample,\n",
    "    process_button,\n",
    "    output_reference\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e5446-efa6-4dde-afba-4d7faf541e94",
   "metadata": {},
   "source": [
    "## Convert by Predefined Library\n",
    "\n",
    "You can also **convert your input to match a predefined speaker ID**. In this case from the VCTK dataset.\n",
    "\n",
    "Simply provide a **speaker ID**, (p225 - p360) and the system will add the vocal characteristics to your input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff99543-2e42-4576-a373-c6b0c7cb01d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b8424b0f694fd59c8c38d23c170d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<b style=\"font-size:14px\">Input Audio</b>'), HTML(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('utils/speaker_dict.json', 'r') as f:\n",
    "    speaker_dict = json.load(f)\n",
    "speaker_ids = sorted(speaker_dict.keys())\n",
    "\n",
    "input_container, input_state = make_audio_picker('Input Audio', 'audio/librispeech2.wav')\n",
    "\n",
    "speaker_selected_label = widgets.HTML(\n",
    "    value=f'<span style=\"color:#555\">üéôÔ∏è Selected: <b>p231</b></span>'\n",
    ")\n",
    "\n",
    "def update_speaker_label(sid):\n",
    "    speaker_selected_label.value = f'<span style=\"color:#1a7a1a\">üéôÔ∏è Selected: <b>{sid}</b></span>'\n",
    "\n",
    "speaker_select = widgets.Select(\n",
    "    options=speaker_ids,\n",
    "    value='p231' if 'p231' in speaker_ids else speaker_ids[0],\n",
    "    rows=8,\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "update_speaker_label(speaker_select.value)\n",
    "\n",
    "def on_speaker_select(change):\n",
    "    update_speaker_label(change['new'])\n",
    "\n",
    "speaker_select.observe(on_speaker_select, names='value')\n",
    "\n",
    "speaker_header = widgets.HTML('<b style=\"font-size:14px\">Speaker ID</b>')\n",
    "speaker_container = widgets.VBox([\n",
    "    widgets.HBox(\n",
    "        [speaker_header, speaker_selected_label],\n",
    "        layout=widgets.Layout(justify_content='space-between', align_items='center', width='100%')\n",
    "    ),\n",
    "    speaker_select,\n",
    "], layout=widgets.Layout(\n",
    "    border='1px solid #ccc',\n",
    "    padding='8px',\n",
    "    margin='4px 0',\n",
    "    border_radius='6px'\n",
    "))\n",
    "\n",
    "process_button = widgets.Button(description='Process Audio', button_style='success')\n",
    "output_embedding = widgets.Output()\n",
    "\n",
    "def process_audio(b):\n",
    "    with output_embedding:\n",
    "        output_embedding.clear_output()\n",
    "        try:\n",
    "            x_np, sr = load_audio_from_state(input_state)\n",
    "            x = torch.tensor(x_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            target = [speaker_select.value]\n",
    "            speaker_embedding_avg, speaker_embedding_one, speaker_mean = get_speaker_embeddings_json(\n",
    "                target, 'utils/speaker_dict.json'\n",
    "            )\n",
    "\n",
    "            print(f\"Input audio: {input_state.value}\")\n",
    "            print(f\"Speaker ID:  {target[0]}\")\n",
    "            print(f\"F0 Mean:     {speaker_mean[0]:.2f}\")\n",
    "            print()\n",
    "\n",
    "            speaker_mean_t        = torch.tensor([speaker_mean[0]], dtype=torch.float32)\n",
    "            speaker_embedding_avg = speaker_embedding_avg[0]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                vc_model.reset_pitch()\n",
    "                vc_model.set_new_speaker_from_embedding(speaker_mean_t, speaker_embedding_avg)\n",
    "                vc_model.set_tremble_depth(torch.zeros(1, dtype=torch.float32))\n",
    "                vc_model.set_ambitus_scaler(torch.ones(1, dtype=torch.float32))\n",
    "                vc_model.set_pitch_mult(torch.ones(1, dtype=torch.float32))\n",
    "\n",
    "            out = vc_model(normalize(x, transform))\n",
    "            display_audios([(\"INPUT\", x, sr), (\"CONVERTED\", out, sr)])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "process_button.on_click(process_audio)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    input_container,\n",
    "    speaker_container,\n",
    "    process_button,\n",
    "    output_embedding\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
